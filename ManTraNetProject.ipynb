{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries \n",
        "All needed libraries to use"
      ],
      "metadata": {
        "id": "tD-lQ8GVIF6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJd8IGYWZUxD"
      },
      "outputs": [],
      "source": [
        "#LIBRERIES\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "from random import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, AveragePooling2D, Concatenate, Multiply, ConvLSTM2D, Lambda, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import layers, Model, regularizers, activations\n",
        "from keras.initializers import Constant\n",
        "from keras.constraints import unit_norm, non_neg\n",
        "from keras import backend as K\n",
        "from keras.engine.base_layer import Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as path_effects\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoJ_wWZ3LkIC"
      },
      "outputs": [],
      "source": [
        "#MOUNT GOOGLE DRIVE \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Useful functions\n",
        "All functions used to deal with data (e.g. load files, define dataset, plot images ad history of the model, etc.)"
      ],
      "metadata": {
        "id": "zc64nbgiISEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBLkfBM3LQj0"
      },
      "outputs": [],
      "source": [
        "#USEFUL FUNCTIONS\n",
        "\n",
        "#Get a list of paths of images from files\n",
        "def getFiles(train, path):\n",
        "    images = []\n",
        "    count = 0\n",
        "    for file in  sorted(os.listdir(path +'/')):\n",
        "        images.append(path + '/'+  file)\n",
        "    return images\n",
        "\n",
        "#Read the images from path\n",
        "def readImage(img_path,size):\n",
        "\n",
        "  img = cv2.imread(img_path) \n",
        "  img = cv2.resize(img,(size,size))\n",
        "\n",
        "  return img\n",
        "\n",
        "#Read the mask (image labels) from path\n",
        "def readMask(img_path,size):\n",
        "\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) \n",
        "  img = cv2.resize(img,(size,size))\n",
        "  img = img.reshape((size,size,1))\n",
        "\n",
        "  return img\n",
        "\n",
        "#Get a list of array of images (or mask) from paths\n",
        "def list_from_files(files, img_size, isMask = False):\n",
        "\n",
        "  l = []\n",
        "\n",
        "  if(isMask):\n",
        "\n",
        "    for mask_path in files:\n",
        "      l.append(readMask(mask_path, img_size))\n",
        "\n",
        "  else:\n",
        "\n",
        "    for img_path in files:\n",
        "      l.append(readImage(img_path, img_size))\n",
        "\n",
        "  return l\n",
        "\n",
        "#Prepare train, validation and test data\n",
        "def dataset(X_train, y_train, train=0.7, validation=0.2, test=0.1):\n",
        "\n",
        "  X_train = np.asarray(X_train)\n",
        "  y_train = np.asarray(y_train)\n",
        "\n",
        "  dim = X_train.shape[0]\n",
        "  n_train = np.int(dim*train)\n",
        "  n_validation = np.int(dim*validation)\n",
        "  n_test = dim - n_train - n_validation\n",
        "\n",
        "  x = X_train[0:n_train]\n",
        "  y = y_train[0:n_train]\n",
        "  x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "  y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "\n",
        "  x_val = X_train[n_train:n_train+n_validation]\n",
        "  y_val = y_train[n_train:n_train+n_validation]\n",
        "  x_val = tf.convert_to_tensor(x_val, dtype=tf.float32)\n",
        "  y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
        "\n",
        "  x_test = X_train[-n_test:]\n",
        "  y_test = y_train[-n_test:]\n",
        "  x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
        "  y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "  print(\"Using: \"+np.str(n_train)+\" images for training\")\n",
        "  print(\"Using: \"+np.str(n_validation)+\" images for validation\")\n",
        "  print(\"Using: \"+np.str(n_test)+\" images for test\")\n",
        "  print(\"For a total of \"+np.str(dim)+\" images found.\")\n",
        "\n",
        "  return x, y, x_val, y_val, x_test, y_test\n",
        "\n",
        "#Predict the mask from an image\n",
        "def predict_mask(model, img_size, train_files, n):\n",
        "\n",
        "  im = readImage(train_files[n], img_size)\n",
        "  im = im.reshape([1, img_size, img_size, 3])\n",
        "  im = tf.convert_to_tensor(im, dtype=tf.float32)\n",
        "  new = model.predict(im)\n",
        "  return np.asarray(new)\n",
        "\n",
        "#Plot images, corresponding mask and predicted mask\n",
        "def plot_samples_predictions(model, x, y, train_files, img_size, n_samples=5):\n",
        "\n",
        "  fig1, imgs = plt.subplots(n_samples, 3, figsize=(15, 15), sharex=True, sharey=True)\n",
        "\n",
        "  for i in range(n_samples):\n",
        "\n",
        "    n = np.random.randint(0,len(x))\n",
        "  \n",
        "    mask = predict_mask(model, img_size, train_files, n)\n",
        "\n",
        "    imgs[i,0].set_title('Image Test')\n",
        "    imgs[i,0].imshow(np.asarray(x[n]), cmap=plt.cm.gray)\n",
        "\n",
        "    imgs[i,1].set_title('Ground Truth')\n",
        "    imgs[i,1].imshow(np.asarray(y[n]).squeeze(), cmap=plt.cm.gray)\n",
        "\n",
        "    imgs[i,2].set_title('Prediction')\n",
        "    imgs[i,2].imshow(mask.squeeze(), cmap=plt.cm.gray)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "#Plot curves of history of training of model (loss, AUC, precision, recall)\n",
        "def plot_history(H):\n",
        "\n",
        "  k = []\n",
        "  for i in H.history.keys():\n",
        "    k.append(i)\n",
        "\n",
        "  loss = k[0]\n",
        "  auc = k[1]\n",
        "  precision = k[2]\n",
        "  recall = k[3]\n",
        "  val_loss = k[4]\n",
        "  val_auc = k[5]\n",
        "  val_precision = k[6]\n",
        "  val_recall = k[7]\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(2, 2,figsize=(15, 10))\n",
        "\n",
        "  ax1[0].set_title('TRANINING LOSS')\n",
        "  ax1[0].set(xlabel='Epoch', ylabel='Loss')\n",
        "  ax1[0].plot(H.history[loss], label='loss')\n",
        "  ax1[0].legend(loc=\"upper left\")\n",
        "\n",
        "  ax1[1].set_title('TRANINING METRICS')\n",
        "  ax1[1].set(xlabel='Epoch', ylabel='Metrics')\n",
        "  ax1[1].plot(H.history[auc], label='AUC')\n",
        "  ax1[1].plot(H.history[precision], label='precision')\n",
        "  ax1[1].plot(H.history[recall], label='recall')\n",
        "  ax1[1].legend(loc=\"upper left\")\n",
        "\n",
        "  ax2[0].set_title(\"VALIDATION LOSS\")\n",
        "  ax2[0].set(xlabel='Epoch', ylabel='Loss')\n",
        "  ax2[0].plot(H.history[val_loss], label='loss')\n",
        "  ax2[0].legend(loc=\"upper left\")\n",
        "\n",
        "  ax2[1].set_title('VALIDATION METRICS')\n",
        "  ax2[1].set(xlabel='Epoch', ylabel='Metrics')\n",
        "  ax2[1].plot(H.history[val_auc], label='AUC')\n",
        "  ax2[1].plot(H.history[val_precision], label='precision')\n",
        "  ax2[1].plot(H.history[val_recall], label='recall')\n",
        "  ax2[1].legend(loc=\"upper left\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "#Plot history (only with loss and accuracy)\n",
        "def plot_history2(H):\n",
        "\n",
        "  k = []\n",
        "  for i in H.history.keys():\n",
        "    k.append(i)\n",
        "\n",
        "  loss = k[0]\n",
        "  acc = k[1]\n",
        "  val_loss = k[2]\n",
        "  val_acc = k[3]\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(2, 2,figsize=(15, 10))\n",
        "\n",
        "  ax1[0].set_title('TRANINING LOSS')\n",
        "  ax1[0].set(xlabel='Epoch', ylabel='Loss')\n",
        "  ax1[0].plot(H.history[loss], label='loss')\n",
        "  ax1[0].legend(loc=\"upper left\")\n",
        "\n",
        "  ax1[1].set_title('TRANINING METRICS')\n",
        "  ax1[1].set(xlabel='Epoch', ylabel='Metrics')\n",
        "  ax1[1].plot(H.history[acc], label='Accuracy')\n",
        "  ax1[1].legend(loc=\"upper left\")\n",
        "\n",
        "  ax2[0].set_title(\"VALIDATION LOSS\")\n",
        "  ax2[0].set(xlabel='Epoch', ylabel='Loss')\n",
        "  ax2[0].plot(H.history[val_loss], label='loss')\n",
        "  ax2[0].legend(loc=\"upper left\")\n",
        "\n",
        "  ax2[1].set_title('VALIDATION METRICS')\n",
        "  ax2[1].set(xlabel='Epoch', ylabel='Metrics')\n",
        "  ax2[1].plot(H.history[val_acc], label='Accuracy')\n",
        "  ax2[1].legend(loc=\"upper left\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "#print evaluation of model on test data\n",
        "def print_model_evaluation(model):\n",
        "\n",
        "  loss, auc, prec, rec = mantranet.evaluate(x_test,y_test)\n",
        "  print(\"Loss: \", loss)\n",
        "  print(\"AUC: \", auc)\n",
        "  print(\"Precision: \", prec)\n",
        "  print(\"Recall: \", rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classes used in the neural network model"
      ],
      "metadata": {
        "id": "mFEk-uI5JGMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1igKYk9efuON"
      },
      "outputs": [],
      "source": [
        "class BayarConstraint(tf.keras.constraints.Constraint):\n",
        "\n",
        "  def __init__(self):\n",
        "    return\n",
        "\n",
        "  def call(self, w):\n",
        "    rows, cols, _, _ = K.int_shape(w)\n",
        "    w[rows//2,cols//2] = 0\n",
        "    sum = K.sum(w, axis=(0,1), keepdims=True)\n",
        "    w /= sum\n",
        "    w[rows//2,cols//2] = -1\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI70CO2FRzwr"
      },
      "outputs": [],
      "source": [
        "class BayarConv2D(Layer):\n",
        "\n",
        "  def __init__(self, filters, kernel_size, padding='SAME', activation=None, kernel_initializer='glorot_uniform',\n",
        "               kernel_regularizer=None, kernel_constraint=BayarConstraint(), trainable=True, name=\"BayarConv2D\"): \n",
        "    super(BayarConv2D, self).__init__(trainable=trainable, name=name)  \n",
        "    self.filters = filters\n",
        "    self.kernel_size = kernel_size\n",
        "    self.kernel_initializer = kernel_initializer\n",
        "    self.kernel_regularizer = kernel_regularizer\n",
        "    self.padding = padding\n",
        "    self.activation = activation\n",
        "    self.kernel_constraint = kernel_constraint\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_shape = tf.TensorShape(input_shape)\n",
        "    input_channel = 3\n",
        "    kernel_shape = self.kernel_size + (input_channel, self.filters)\n",
        "    self.kernel = self.add_weight(name='kernel',\n",
        "                                  shape=kernel_shape,\n",
        "                                  initializer=self.kernel_initializer,\n",
        "                                  regularizer=self.kernel_regularizer,\n",
        "                                  constraint=self.kernel_constraint,\n",
        "                                  trainable=True,\n",
        "                                  dtype=self.dtype)\n",
        "    self.built = True\n",
        "\n",
        "  def get_kernel(self):\n",
        "    return self.kernel\n",
        "\n",
        "  def call(self, inputs):\n",
        "    outputs = tf.nn.convolution(inputs, self.kernel, padding=self.padding)\n",
        "    if self.activation is not None:\n",
        "      act = layers.Activation(self.activation)\n",
        "      return act(outputs)\n",
        "  \n",
        "    return self.kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0LYuOR9B5lO"
      },
      "outputs": [],
      "source": [
        "class SRMConv2D(Layer):\n",
        "\n",
        "  def __init__(self, filters = 3, kernel_size = (5,5), padding='SAME', activation=\"relu\",\n",
        "               kernel_initializer='glorot_uniform', trainable=True, name=\"SRMConv2D\"):\n",
        "    super(SRMConv2D, self).__init__(trainable=trainable, name=name)   \n",
        "    self.filters = filters  \n",
        "    self.padding = padding\n",
        "    self.activation = activation  \n",
        "    self.kernel = []\n",
        "\n",
        "    #srm kernel 1\n",
        "    self.srm1 = np.zeros([5,5]).astype('float32')\n",
        "    self.srm1[1:-1,1:-1] = np.array([[-1, 2, -1],\n",
        "                                  [2, -4, 2],\n",
        "                                  [-1, 2, -1]] )\n",
        "    self.srm1 /= 4.\n",
        "\n",
        "    #srm kernel 2                                                                                                                                \n",
        "    self.srm2 = np.array([[-1, 2, -2, 2, -1],\n",
        "                        [2, -6, 8, -6, 2],\n",
        "                        [-2, 8, -12, 8, -2],\n",
        "                        [2, -6, 8, -6, 2],\n",
        "                        [-1, 2, -2, 2, -1]]).astype('float32')\n",
        "    self.srm2 /= 12.\n",
        "\n",
        "    # srm kernel 3                                                                                                                                \n",
        "    self.srm3 = np.zeros([5,5]).astype('float32')\n",
        "    self.srm3[2,1:-1] = np.array([1,-2,1])\n",
        "    self.srm3 /= 2.\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    kernel = []\n",
        "    srm_list = [self.srm1, self.srm2, self.srm3]\n",
        "    for idx, srm in enumerate(srm_list):\n",
        "      for ch in range(3) :\n",
        "        this_ch_kernel = np.zeros([5,5,3]).astype('float32')\n",
        "        this_ch_kernel[:,:,ch] = srm\n",
        "        kernel.append( this_ch_kernel )\n",
        "    kernel = np.stack( kernel, axis=-1 )\n",
        "    self.kernel = K.variable(kernel, dtype='float32', name='srm')\n",
        "\n",
        "    self.built = True\n",
        "\n",
        "  def get_kernel(self):\n",
        "    return self.kernel\n",
        "\n",
        "  def call(self, inputs):  \n",
        "    outputs = tf.nn.convolution(inputs, self.kernel, padding=self.padding)\n",
        "    if self.activation is not None:\n",
        "      return self.activation(outputs)\n",
        "    \n",
        "    return self.kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Bnnhl_IWr0"
      },
      "outputs": [],
      "source": [
        "class GlobalStd2D( Layer ) :\n",
        "\n",
        "    def __init__(self, min_std_val=1e-5, name=\"GlobalStd2D\"):\n",
        "        self.min_std_val = min_std_val\n",
        "        super(GlobalStd2D, self ).__init__()\n",
        "\n",
        "    def build( self, input_shape ) :\n",
        "        feats = input_shape[-1]\n",
        "        std_shape = (1,1,1, feats)\n",
        "        self.min_std = self.add_weight( shape=std_shape,\n",
        "                                        initializer=Constant(self.min_std_val),\n",
        "                                        name='min_std',\n",
        "                                        constraint=non_neg())\n",
        "        self.built = True\n",
        "\n",
        "    def call( self, x ) :\n",
        "        x_std = K.std( x, axis=(1,2), keepdims=True )\n",
        "        x_std = K.maximum( x_std, self.min_std_val/10. + self.min_std )\n",
        "        return x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSbsn7xCBPSw"
      },
      "outputs": [],
      "source": [
        "class ZPool2D(Layer):\n",
        "\n",
        "  def __init__(self, win_size, filters = None, name=\"ZPool2D\"):  \n",
        "    super(ZPool2D, self).__init__(name=name)\n",
        "    self.win_size = win_size\n",
        "\n",
        "  def call(self, input, globalPool=False):\n",
        "    avgs = []\n",
        "    for dim in self.win_size:\n",
        "\n",
        "      avg = AveragePooling2D(pool_size=(dim,dim), strides=(1, 1), data_format='channels_last', padding='same')\n",
        "      mu = avg(input)\n",
        "      d = input-mu\n",
        "      avgs.append(d)\n",
        "\n",
        "    if(globalPool==True):\n",
        "      mu = K.mean( input, axis=(1,2), keepdims=True )\n",
        "      d = input-mu\n",
        "      avgs.append(d) \n",
        "\n",
        "    avgs = K.stack(avgs, axis=1)\n",
        "\n",
        "    return avgs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters to use in the model"
      ],
      "metadata": {
        "id": "ED3PowMqJsXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OmFVAPwqhcE"
      },
      "outputs": [],
      "source": [
        "#HYPERPARAMETERS\n",
        "\n",
        "IMG_SIZE = 90\n",
        "EPOCHS = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "pad = \"same\"\n",
        "opt = Adam(learning_rate=learning_rate)\n",
        "loss_f = \"categorical_crossentropy\"\n",
        "metrics = [tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "metrics_imc = \"accuracy\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and prepare data"
      ],
      "metadata": {
        "id": "0KzhDBEOJkI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNwARLJWNMsn"
      },
      "outputs": [],
      "source": [
        "#DATASET PATH\n",
        "casia_imgs_path = \"/content/drive/MyDrive/myDataset/CM\"\n",
        "casia_mask_path = \"/content/drive/MyDrive/myDataset/GT\"\n",
        "\n",
        "#LOAD DATA\n",
        "imgs_train_files = getFiles(False, casia_imgs_path)\n",
        "mask_train_files = getFiles(False, casia_mask_path)\n",
        "imgs_list = list_from_files(imgs_train_files, IMG_SIZE)\n",
        "mask_list = list_from_files(imgs_train_files, IMG_SIZE, isMask=True)\n",
        "\n",
        "#ORGANIZE DATASET FOR MANTRANET TASK\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = dataset(imgs_list, mask_list)\n",
        "print(\"Shape of trainig: \"+np.str(x_train.shape)+\" - \"+np.str(y_train.shape))\n",
        "print(\"Shape of validation: \"+np.str(x_val.shape)+\" - \"+np.str(y_val.shape))\n",
        "print(\"Shape of test: \"+np.str(x_test.shape)+\" - \"+np.str(y_test.shape))\n",
        "\n",
        "#ORGANIZE DATASET FOR IMC TASK\n",
        "path_imc = \"/content/drive/MyDrive/myIMCdataset\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_imc = train_datagen.flow_from_directory(path_imc, target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                          batch_size=batch_size, class_mode='categorical', subset='training')\n",
        "val_imc = train_datagen.flow_from_directory(path_imc, target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                         batch_size=batch_size, class_mode='categorical', subset='validation')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_imc = test_datagen.flow_from_directory(path_imc, target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                         batch_size=batch_size, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First implementation of the model in a class\n",
        "\n",
        "Here all layers are implemented in a class building a single model"
      ],
      "metadata": {
        "id": "kRJXI4W6J5fu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0Rfqs3jrxl"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTATION OF THE MODEL IN A CLASS\n",
        "\n",
        "class ManTraNet(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ManTraNet, self).__init__()\n",
        "    \n",
        "    self.conv1 = Conv2D(10, (5,5), input_shape=(IMG_SIZE, IMG_SIZE, 3), padding=pad, activation=\"relu\")\n",
        "    self.bayar_conv = BayarConv2D(3, (5,5), activation=activations.relu)\n",
        "    self.srm_conv = SRMConv2D(activation=activations.relu)\n",
        "\n",
        "    self.conv2 = Conv2D(32, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv3 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv4 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv5 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv6 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv7 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv8 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv9 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv10 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv11 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv12 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv13 = Conv2D(256, (3,3), padding=pad, activation=None, activity_regularizer=regularizers.l2(1e-5))\n",
        "\n",
        "    self.conv14 = Conv2D(64, (1,1), activation=None, use_bias=False, kernel_constraint = unit_norm( axis=-2 ), padding=pad)\n",
        "    self.bn = BatchNormalization(axis=-1, center=True, scale=True, name=\"bn1\")\n",
        "\n",
        "    self.conv15 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv16 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.bn2 = BatchNormalization(axis=-1, center=True, scale=True, name=\"bn2\")\n",
        "\n",
        "    self.globalstd = GlobalStd2D()\n",
        "    self.ZPool = ZPool2D(win_size=[7,15,31])\n",
        "    self.conv_lstm = ConvLSTM2D(8, (7,7), activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "                                padding='same', name='cLSTM', return_sequences=False)\n",
        "    \n",
        "    self.conv_last = Conv2D(1, (7,7), padding=pad, activation=\"sigmoid\")\n",
        "\n",
        "  def call(self, input):\n",
        "\n",
        "    x1 = self.conv1(input)\n",
        "    x2 = self.bayar_conv(input)\n",
        "    x3 = self.srm_conv(input)\n",
        "\n",
        "    x = [x1,x2,x3]\n",
        "    x = K.concatenate(x, axis=-1)\n",
        "    \n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    #Dropout(0.3)\n",
        "    x = self.conv5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.conv7(x)\n",
        "    #Dropout(0.2)\n",
        "    x = self.conv8(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.conv10(x)\n",
        "    #Dropout(0.3)\n",
        "    x = self.conv11(x)\n",
        "    x = self.conv12(x)\n",
        "    x = self.conv13(x)\n",
        "    #Dropout(0.2)\n",
        "\n",
        "    x = Lambda(lambda t : K.l2_normalize( t, axis=-1), name='L2')(x)\n",
        "\n",
        "    x = self.conv14(x)\n",
        "    x = self.bn(x)\n",
        "\n",
        "    #new\n",
        "    #x = self.conv15(x)\n",
        "    #x = self.conv14(x)\n",
        "    #x = self.bn2(x)\n",
        "\n",
        "    #ZPool + LSTM layers \n",
        "    zpool_windows = self.ZPool(x, globalPool=True)\n",
        "    sigma = self.globalstd(x)\n",
        "    sigma = Lambda( lambda t : K.expand_dims( t, axis=1 ), name='sigma')( sigma )\n",
        "    zf = Lambda( lambda vs : K.abs(vs[0]/vs[1]), name='ZPool' )([zpool_windows, sigma])\n",
        "    x = self.conv_lstm(zf)\n",
        "    \n",
        "    output = self.conv_last(x)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second implementation of the model\n",
        "Here, as suggested in the paper, the model is divided in two sub-model, the first one inspired to VGG network, useful for Image Manipulation Classification (IMC) and used to Image manipulation feature extraction, the second one include a ZPool layer inspired to a human reasoning to local anomaly detection.\n",
        "\n",
        "P.S.: The layers and the structure of this 2 sub-models and the previous  all-in-one model are equal."
      ],
      "metadata": {
        "id": "UWjzhmr6KIoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IMC(Model):\n",
        "\n",
        "  def __init__(self, classification, k):\n",
        "    super(IMC, self).__init__()\n",
        "\n",
        "    self.classification = classification\n",
        "    self.k = k\n",
        "\n",
        "    self.conv1 = Conv2D(10, (5,5), input_shape=(IMG_SIZE, IMG_SIZE, 3), padding=pad, activation=\"relu\")\n",
        "    self.bayar_conv = BayarConv2D(3, (5,5), activation=activations.relu)\n",
        "    self.srm_conv = SRMConv2D(activation=activations.relu)\n",
        "\n",
        "    self.conv2 = Conv2D(32, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv3 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv4 = Conv2D(64, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv5 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv6 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv7 = Conv2D(128, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv8 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv9 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv10 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv11 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv12 = Conv2D(256, (3,3), padding=pad, activation=\"relu\")\n",
        "    self.conv13 = Conv2D(64, (3,3), padding=pad, activation=None, activity_regularizer=regularizers.l2(1e-5))\n",
        "\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1 = Dense(64, activation=\"relu\")\n",
        "    self.dense2 = Dense(self.k, activation=\"softmax\")\n",
        "\n",
        "  def set_classification(self, classification):\n",
        "    self.classification = classification\n",
        "\n",
        "  def call(self, input):\n",
        "    \n",
        "    x1 = self.conv1(input)\n",
        "    x2 = self.bayar_conv(input)\n",
        "    x3 = self.srm_conv(input)\n",
        "\n",
        "    x = [x1,x2,x3]\n",
        "    x = K.concatenate(x, axis=-1)\n",
        "    \n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.conv11(x)\n",
        "    x = self.conv12(x)\n",
        "    x = self.conv13(x)\n",
        "    x = Lambda(lambda t : K.l2_normalize( t, axis=-1), name='L2')(x)\n",
        "\n",
        "    if self.classification:\n",
        "      x = self.flatten(x)\n",
        "      x = self.dense1(x)\n",
        "      x = self.dense2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "T9pupcNN7sbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mantranet_model(first_block, pool_size_list):\n",
        "\n",
        "    img = Input(shape=(None,None,3), name='imput')\n",
        "    out = first_block(img)\n",
        "    out = Conv2D(64, (1,1), activation=None, use_bias=False, kernel_constraint = unit_norm( axis=-2 ), padding=pad)(out)\n",
        "    out = BatchNormalization(axis=-1, center=True, scale=True, name=\"bn1\")(out)\n",
        "\n",
        "    sigma = GlobalStd2D(name='glbStd')(out)\n",
        "    sigma = Lambda( lambda t : K.expand_dims( t, axis=1 ), name='sigma')( sigma )\n",
        "    zpool_windows = ZPool2D(pool_size_list)(out, globalPool = True)\n",
        "    zf = Lambda(lambda vs : K.abs(vs[0]/vs[1]), name='ZPool')([zpool_windows, sigma])\n",
        "\n",
        "    out = ConvLSTM2D(8, (7,7), activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "                     padding='same', name='cLSTM', return_sequences=False)(zf)\n",
        "\n",
        "    output = Conv2D(1, (7,7), padding=pad, activation=\"sigmoid\")(out)\n",
        "\n",
        "    return Model(inputs=img, outputs=output, name='mantranet')"
      ],
      "metadata": {
        "id": "PDdaWGqN-Hfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build and compile models"
      ],
      "metadata": {
        "id": "L8bfdvSVNs8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMBvrCZZ3vXX"
      },
      "outputs": [],
      "source": [
        "#BUILD AND COMPILE A NEW (ALL-IN-ONE) MODEL\n",
        "\n",
        "mantranet = ManTraNet()\n",
        "mantranet.build([batch_size, IMG_SIZE, IMG_SIZE, 3])\n",
        "mantranet.summary()\n",
        "mantranet.compile(optimizer=opt, loss=loss_f, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BUILD AND COMPILE A NEW IMC MODEL\n",
        "\n",
        "imc = IMC(True, 7)\n",
        "imc.build([batch_size, IMG_SIZE, IMG_SIZE, 3])\n",
        "imc.summary()\n",
        "imc.compile(optimizer=opt, loss=loss_f, metrics=metrics)"
      ],
      "metadata": {
        "id": "BgpdwcohNyvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BUILD AND COMPILE A NEW MODEL USING PREVIOUS IMC MODEL\n",
        "\n",
        "imc.trainable=False\n",
        "imc.set_classification(False)\n",
        "mantranet = mantranet_model(imc, [7,15,31])\n",
        "mantranet = ManTraNet()\n",
        "mantranet.build([batch_size, IMG_SIZE, IMG_SIZE, 3])\n",
        "mantranet.summary()\n",
        "mantranet.compile(optimizer=opt, loss=loss_f, metrics=metrics_imc)"
      ],
      "metadata": {
        "id": "NPC1UOwQEbVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cell to load pre-trained weights"
      ],
      "metadata": {
        "id": "vQOOokoIOWea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZnSMC2xLGad"
      },
      "outputs": [],
      "source": [
        "#LOAD PRE-TRAINED WEIGHTS (IF NEEDED)\n",
        "mantranet.load_weights(\"/content/drive/MyDrive/Mantra_weights/model_3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train a model"
      ],
      "metadata": {
        "id": "ns_rmDbGOjMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN THE MODEL\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "History=imc.fit(train_imc, epochs=EPOCHS, batch_size=batch_size, verbose=1, validation_data=val_imc)"
      ],
      "metadata": {
        "id": "8oJ42VDhOMkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgwnRtia94Ur"
      },
      "outputs": [],
      "source": [
        "#TRAIN THE MODEL\n",
        "History=mantranet.fit(x_train, y_train, epochs=EPOCHS, batch_size=batch_size, verbose=1, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cell to save weights"
      ],
      "metadata": {
        "id": "21LlqKtSO0wR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROm3Jg_5q4Me"
      },
      "outputs": [],
      "source": [
        "#SAVE TRAINED WEIGHTS\n",
        "mantranet.save_weights(\"/content/drive/MyDrive/Mantra_weights/model_11.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imc.save_weights(\"/content/drive/MyDrive/Mantra_weights/imc.h5\")"
      ],
      "metadata": {
        "id": "EwGvFhBLpmyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot evaluation, predictions and history of training of the model"
      ],
      "metadata": {
        "id": "XGo2uuntPvjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGvHZBunCJY3"
      },
      "outputs": [],
      "source": [
        "#TEST OF THE MODEL\n",
        "print_model_evaluation(mantranet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT_0M6O99BQf"
      },
      "outputs": [],
      "source": [
        "#PLOT ORIGINAL IMAGE WITH GROUND TRUTH AND PREDICTED MASK\n",
        "plot_samples_predictions(mantranet, imgs_list, mask_list, imgs_train_files, IMG_SIZE, n_samples=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUNNh2UmmZs"
      },
      "outputs": [],
      "source": [
        "#PLOT TRAINING HISTORY OF THE MODEL\n",
        "plot_history(History)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST OF THE MODEL\n",
        "loss, acc = imc.evaluate(test_imc)\n",
        "\n",
        "print(\"Loss: \"+np.str(loss))\n",
        "print(\"Accuracy: \"+np.str(acc))"
      ],
      "metadata": {
        "id": "aBHOQYrmkBrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOT TRAINING HISTORY OF THE MODEL\n",
        "plot_history2(History)"
      ],
      "metadata": {
        "id": "p9u8a7uuqjkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ManTraNetProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}